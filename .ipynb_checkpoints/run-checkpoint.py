{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torchvision # torch package for vision related things\n",
    "import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n",
    "import torchvision.datasets as datasets  # Standard datasets\n",
    "import torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\n",
    "from torch import optim  # For optimizers like SGD, Adam, etc.\n",
    "from torch import nn  # All neural network modules\n",
    "from torch.utils.data import DataLoader  # Gives easier dataset managment by creating mini batches etc.\n",
    "from tqdm import tqdm  # For nice progress bar!\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn\n",
    "\n",
    "\"\"\"\n",
    "(Hyper)parameters of our convolutional neural network found by tuning with Ray Tune (see further on)\n",
    "\n",
    "\"\"\"\n",
    "input_size = 3 * 100\n",
    "num_classes = 3\n",
    "learning_rate = 0.017287600194096035\n",
    "batch_size = 10\n",
    "num_epochs = 5\n",
    "\n",
    "\"\"\"\n",
    "Multi-Layer Perceptron\n",
    "Class inherits from nn.Module, a pytorch neural network of choice, must inherit from base class nn.Module.\n",
    "\"\"\"\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size = input_size, num_classes = num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 50)\n",
    "        self.fc2 = nn.Linear(50, 25)\n",
    "        self.fc3 = nn.Linear(25, 10)\n",
    "        self.fc4 = nn.Linear(10, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward propagation function.\n",
    "        \n",
    "        self: self\n",
    "        x: tensor of shape (3, 100) (klopt dit?)\n",
    "        \n",
    "        returns: tensor of shape (1, num_classes) serving as a feature vector.\n",
    "        \"\"\"\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        #softmax?\n",
    "        return x\n",
    "\n",
    "\"\"\"\n",
    "Set device cuda for GPU if it's available otherwise run on the CPU\n",
    "\"\"\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\"\"\"\n",
    "Load labels from csv file\n",
    "\"\"\"\n",
    "labels = np.genfromtxt('/Data/Labels/avg_smooth.csv', delimiter=',')\n",
    "\n",
    "\"\"\"\n",
    "Make labels categorical: 3 quantification levels\n",
    "\"\"\"\n",
    "df_labels = pd.DataFrame(labels)\n",
    "df_labels = pd.cut(df_labels[0],bins=[0, 0.012, 0.02, 0.03],labels=[0,1,2])\n",
    "labels = df_labels.to_numpy()\n",
    "\n",
    "\"\"\"\n",
    "Load .npy files into one big array\n",
    "\"\"\"\n",
    "data = []\n",
    "dir = '/Data/input_MLP/'\n",
    "pac = np.load('/Data/PAC_afterCNN.npy')\n",
    "for filename in os.listdir(dir):\n",
    "    sample = np.load(dir+filename)\n",
    "    data.append(sample.flatten())\n",
    "data = np.array(data)\n",
    "\n",
    "\"\"\"\n",
    "Transform data to torch tensors\n",
    "\"\"\"\n",
    "tensor_x = torch.Tensor(data)\n",
    "tensor_y = torch.Tensor(labels)\n",
    "tensor_y = tensor_y.type(torch.LongTensor)\n",
    "\n",
    "\"\"\"\n",
    "Create dataset and data loader\n",
    "\"\"\"\n",
    "dataset = TensorDataset(tensor_x,tensor_y)\n",
    "\n",
    "\"\"\"\n",
    "Split into train and test sets\n",
    "\"\"\"\n",
    "test_size = int(0.3*len(dataset))\n",
    "train_size = len(dataset) - test_size\n",
    "\n",
    "train_data,test_data = random_split(dataset,[train_size,test_size])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size, shuffle = False, num_workers = 4, pin_memory = True)\n",
    "test_loader = DataLoader(test_data, batch_size, shuffle = False, num_workers = 4, pin_memory = True)\n",
    "\n",
    "\"\"\"\n",
    "Initialize network\n",
    "\"\"\" \n",
    "model = MLP(input_size, num_classes).to(device)\n",
    "\"\"\"\n",
    "Loss and optimizer\n",
    "\"\"\" \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\"\"\"\n",
    " Accuracy function.\n",
    "\n",
    " Check accuracy on training & test to see how good the model is\n",
    " \n",
    " loader: a pytorch dataloader\n",
    " model: a pytorch model\n",
    " \n",
    " returns: model accuracy as a numerical value\n",
    "\"\"\"\n",
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            #x = x.reshape(x.shape[0], -1)\n",
    "\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "    model.train()\n",
    "    return num_correct/num_samples\n",
    "\n",
    "\"\"\"\n",
    "Define the 5-fold Cross Validator\n",
    "\"\"\"\n",
    "k_folds = 5\n",
    "kfold = KFold(n_splits=k_folds, shuffle=False)\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "    print(f'Fold {fold}')\n",
    "    model.apply(reset_weights)\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                      dataset, batch_size=10, sampler=train_subsampler)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                      dataset, batch_size=10, sampler=test_subsampler)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_idx, (input_, labels) in enumerate(tqdm(trainloader)):\n",
    "            # Get data to cuda if possible\n",
    "            input_ = input_.to(device=device)\n",
    "            targets = labels.to(device=device)\n",
    "\n",
    "            # forward\n",
    "            scores = model(input_)\n",
    "            loss = criterion(scores, targets)\n",
    "\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # gradient descent or adam step\n",
    "            optimizer.step()\n",
    "        train_acc.append(check_accuracy(trainloader, model).item()*100)\n",
    "        test_acc.append(check_accuracy(testloader, model).item()*100)\n",
    "    print('Train Accuracy for fold %d: %d %%' % (fold, 100.0 * check_accuracy(trainloader, model)))\n",
    "    print('Test Accuracy for fold %d: %d %%' % (fold, 100.0 * check_accuracy(testloader, model)))\n",
    "print('Averaged Train Accuracy over %d k-folds: %d %%' % (k_folds, np.array(train_acc).mean()))\n",
    "print('Averaged Test Accuracy over %d k-folds: %d %%' % (k_folds, np.array(test_acc).mean()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
